{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac7cf86-79a5-46db-b085-f074dba55760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from citylearn.agents.sac import SAC as RLAgent\n",
    "from agents.user_agent import SubmissionAgent\n",
    "from citylearn.citylearn import CityLearnEnv, EvaluationCondition\n",
    "import os\n",
    "from citylearn.utilities import read_json\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4530330a-33e9-4fcd-82b4-79ca2cb083a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/amalnamm/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c25bb4-bad4-4138-b1df-faf7a6bba6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_filepath = '/home/amalnamm/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit/data/schemas/warm_up/schema.json'\n",
    "schema = read_json(schema_filepath)\n",
    "schema['root_directory'] = '/home/amalnamm/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit/data/schemas/warm_up'\n",
    "env = CityLearnEnv(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22972de1-a8a2-4c03-83c8-887bf8a54f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#env = CityLearnEnv(schema, central_agent=False)\n",
    "model = RLAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995550eb-1f5a-4df9-b974-8f45d1f0f2b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.learn(episodes=20, deterministic_finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ce68366-df34-4a1a-9821-6d7481eff354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.2980286 ,  0.02175603,  0.20513143,  0.13388534, -0.20065843,\n",
       "         0.2166086 , -0.272323  ,  0.0151508 ,  0.1602354 ], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(observations, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e3c8f2-b597-46b7-87b7-376117c35f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Building_1</th>\n",
       "      <th>Building_2</th>\n",
       "      <th>Building_3</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annual_normalized_unserved_energy_total</th>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.012966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_peak_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbon_emissions_total</th>\n",
       "      <td>0.758615</td>\n",
       "      <td>0.973249</td>\n",
       "      <td>0.841478</td>\n",
       "      <td>0.857781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_total</th>\n",
       "      <td>0.746111</td>\n",
       "      <td>0.950684</td>\n",
       "      <td>0.820556</td>\n",
       "      <td>0.839117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_one_minus_load_factor_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.031697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_peak_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_delta_average</th>\n",
       "      <td>1.028429</td>\n",
       "      <td>0.358476</td>\n",
       "      <td>0.480491</td>\n",
       "      <td>0.622465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_delta_maximum</th>\n",
       "      <td>5.435999</td>\n",
       "      <td>5.039425</td>\n",
       "      <td>4.342920</td>\n",
       "      <td>4.939448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_delta_minimum</th>\n",
       "      <td>-1.606436</td>\n",
       "      <td>-1.985348</td>\n",
       "      <td>-1.160789</td>\n",
       "      <td>-1.584191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_proportion</th>\n",
       "      <td>0.126227</td>\n",
       "      <td>0.100746</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>0.081759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_too_cold_proportion</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discomfort_too_hot_proportion</th>\n",
       "      <td>0.126227</td>\n",
       "      <td>0.100746</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>0.081759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity_consumption_total</th>\n",
       "      <td>0.767228</td>\n",
       "      <td>0.976906</td>\n",
       "      <td>0.850879</td>\n",
       "      <td>0.865004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_one_minus_load_factor_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.024787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one_minus_thermal_resilience_proportion</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.344444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_outage_normalized_unserved_energy_total</th>\n",
       "      <td>0.510928</td>\n",
       "      <td>0.563200</td>\n",
       "      <td>0.526485</td>\n",
       "      <td>0.533538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramping_average</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_net_energy</th>\n",
       "      <td>0.744690</td>\n",
       "      <td>0.970024</td>\n",
       "      <td>0.851245</td>\n",
       "      <td>0.855320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                           Building_1  Building_2  \\\n",
       "cost_function                                                           \n",
       "annual_normalized_unserved_energy_total          0.013306    0.012520   \n",
       "annual_peak_average                                   NaN         NaN   \n",
       "carbon_emissions_total                           0.758615    0.973249   \n",
       "cost_total                                       0.746111    0.950684   \n",
       "daily_one_minus_load_factor_average                   NaN         NaN   \n",
       "daily_peak_average                                    NaN         NaN   \n",
       "discomfort_delta_average                         1.028429    0.358476   \n",
       "discomfort_delta_maximum                         5.435999    5.039425   \n",
       "discomfort_delta_minimum                        -1.606436   -1.985348   \n",
       "discomfort_proportion                            0.126227    0.100746   \n",
       "discomfort_too_cold_proportion                   0.000000    0.000000   \n",
       "discomfort_too_hot_proportion                    0.126227    0.100746   \n",
       "electricity_consumption_total                    0.767228    0.976906   \n",
       "monthly_one_minus_load_factor_average                 NaN         NaN   \n",
       "one_minus_thermal_resilience_proportion          0.333333    0.500000   \n",
       "power_outage_normalized_unserved_energy_total    0.510928    0.563200   \n",
       "ramping_average                                       NaN         NaN   \n",
       "zero_net_energy                                  0.744690    0.970024   \n",
       "\n",
       "name                                           Building_3  District  \n",
       "cost_function                                                        \n",
       "annual_normalized_unserved_energy_total          0.013073  0.012966  \n",
       "annual_peak_average                                   NaN  0.937381  \n",
       "carbon_emissions_total                           0.841478  0.857781  \n",
       "cost_total                                       0.820556  0.839117  \n",
       "daily_one_minus_load_factor_average                   NaN  1.031697  \n",
       "daily_peak_average                                    NaN  0.897951  \n",
       "discomfort_delta_average                         0.480491  0.622465  \n",
       "discomfort_delta_maximum                         4.342920  4.939448  \n",
       "discomfort_delta_minimum                        -1.160789 -1.584191  \n",
       "discomfort_proportion                            0.018303  0.081759  \n",
       "discomfort_too_cold_proportion                   0.000000  0.000000  \n",
       "discomfort_too_hot_proportion                    0.018303  0.081759  \n",
       "electricity_consumption_total                    0.850879  0.865004  \n",
       "monthly_one_minus_load_factor_average                 NaN  1.024787  \n",
       "one_minus_thermal_resilience_proportion          0.200000  0.344444  \n",
       "power_outage_normalized_unserved_energy_total    0.526485  0.533538  \n",
       "ramping_average                                       NaN  0.987504  \n",
       "zero_net_energy                                  0.851245  0.855320  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate\n",
    "observations = env.reset()\n",
    "\n",
    "while not env.done:\n",
    "    actions = model.predict(observations, deterministic=True)\n",
    "    observations, _, _, _ = env.step(actions)\n",
    "\n",
    "kpis = env.evaluate()\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value')\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eebea48c-b142-457c-aa1e-a9f547bc0210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = env.evaluate_citylearn_challenge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6088f557-013a-425c-a9c8-e1d23d5e471c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbon_emissions_total': {'display_name': 'Carbon emissions',\n",
       "  'weight': 0.1,\n",
       "  'value': 0.8577808452513612},\n",
       " 'discomfort_proportion': {'display_name': 'Unmet hours',\n",
       "  'weight': 0.3,\n",
       "  'value': 0.3627893848300788},\n",
       " 'ramping_average': {'display_name': 'Ramping',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9875038413612934},\n",
       " 'daily_one_minus_load_factor_average': {'display_name': 'Load factor',\n",
       "  'weight': 0.075,\n",
       "  'value': 1.0316970146552527},\n",
       " 'daily_peak_average': {'display_name': 'Daily peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.8979514847323042},\n",
       " 'annual_peak_average': {'display_name': 'All-time peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9373813819769057},\n",
       " 'one_minus_thermal_resilience_proportion': {'display_name': 'Thermal resilience',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.6428571428571429},\n",
       " 'power_outage_normalized_unserved_energy_total': {'display_name': 'Unserved energy',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.5335377762135185},\n",
       " 'average_score': {'display_name': 'Score',\n",
       "  'weight': None,\n",
       "  'value': 0.6601642}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d29af1ba-46b4-43a6-92b4-71a6df15d506",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SAC' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msac_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SAC' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model.save(\"sac_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a53e918-b716-4df5-a0dc-37d602699fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save({\n",
    "    'model_state_dict': model.policy_net[0].state_dict(),\n",
    "    # ... add any other things you want to save\n",
    "}, \"final_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b95162-0095-4a82-9fae-2c2ffeeb9edb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbon_emissions_total': {'display_name': 'Carbon emissions',\n",
       "  'weight': 0.1,\n",
       "  'value': 0.9516948510682978},\n",
       " 'discomfort_proportion': {'display_name': 'Unmet hours',\n",
       "  'weight': 0.3,\n",
       "  'value': 0.7042784847097007},\n",
       " 'ramping_average': {'display_name': 'Ramping',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.8820170204710601},\n",
       " 'daily_one_minus_load_factor_average': {'display_name': 'Load factor',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9432779693167079},\n",
       " 'daily_peak_average': {'display_name': 'Daily peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9286474542897546},\n",
       " 'annual_peak_average': {'display_name': 'All-time peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9484990488028759},\n",
       " 'one_minus_thermal_resilience_proportion': {'display_name': 'Thermal resilience',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.6380952380952382},\n",
       " 'power_outage_normalized_unserved_energy_total': {'display_name': 'Unserved energy',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.624421237790722},\n",
       " 'average_score': {'display_name': 'Score',\n",
       "  'weight': None,\n",
       "  'value': 0.7735137}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30b8c44-e433-47fa-8c40-9e7d362b407a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WrapperEnv:\n",
    "    \"\"\"\n",
    "    Env to wrap provide Citylearn Env data without providing full env\n",
    "    Preventing attribute access outside of the available functions\n",
    "    \"\"\"\n",
    "    def __init__(self, env_data):\n",
    "        self.observation_names = env_data['observation_names']\n",
    "        self.action_names = env_data['action_names']\n",
    "        self.observation_space = env_data['observation_space']\n",
    "        self.action_space = env_data['action_space']\n",
    "        self.time_steps = env_data['time_steps']\n",
    "        self.seconds_per_time_step = env_data['seconds_per_time_step']\n",
    "        self.random_seed = env_data['random_seed']\n",
    "        self.buildings_metadata = env_data['buildings_metadata']\n",
    "        self.episode_tracker = env_data['episode_tracker']\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        return {'buildings': self.buildings_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a99818-3ac4-4fe9-b8cf-dfe4805037e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rewards.user_reward import SubmissionReward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1b7c26-2c5b-494e-bc68-00e8c26e51f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_citylearn_env(schema, reward_function):\n",
    "    env = CityLearnEnv(schema, reward_function=reward_function,central_agent=False)\n",
    "\n",
    "    env_data = dict(\n",
    "        observation_names = env.observation_names,\n",
    "        action_names = env.action_names,\n",
    "        observation_space = env.observation_space,\n",
    "        action_space = env.action_space,\n",
    "        time_steps = env.time_steps,\n",
    "        random_seed = 1234,\n",
    "        episode_tracker = None,\n",
    "        seconds_per_time_step = None,\n",
    "        buildings_metadata = env.get_metadata()['buildings']\n",
    "    )\n",
    "\n",
    "    wrapper_env = WrapperEnv(env_data)\n",
    "    return env, wrapper_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e53304d7-b252-439e-9b9b-5393830a1495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env, wrapper_env = create_citylearn_env(schema, SubmissionReward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac15dbd1-16fe-4206-9575-eba6793f6c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#agent = RLAgent(env)\n",
    "agent = RLAgent(wrapper_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48dd11ac-d812-4666-bebc-7a91f6a5d660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "episodes = 1\n",
    "deterministic_finish = True\n",
    "deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e022dc2-25a4-4ca6-81dd-ae976e3f7e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observations = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ea3ee4-515f-4ca3-8cab-584eec690dac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local evaluation\n",
      "Env Created\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "environment number of time steps: 720\n",
      "Episode complete: 1 | Latest episode metrics: {'carbon_emissions_total': {'display_name': 'Carbon emissions', 'weight': 0.1, 'value': 1.0236161639934387}, 'discomfort_proportion': {'display_name': 'Unmet hours', 'weight': 0.3, 'value': 0.7475733667228938}, 'ramping_average': {'display_name': 'Ramping', 'weight': 0.075, 'value': 1.4532395577618051}, 'daily_one_minus_load_factor_average': {'display_name': 'Load factor', 'weight': 0.075, 'value': 1.0055683512574216}, 'daily_peak_average': {'display_name': 'Daily peak', 'weight': 0.075, 'value': 1.0198278961376186}, 'annual_peak_average': {'display_name': 'All-time peak', 'weight': 0.075, 'value': 0.8896586133342391}, 'one_minus_thermal_resilience_proportion': {'display_name': 'Thermal resilience', 'weight': 0.15, 'value': 0.6142857142857143}, 'power_outage_normalized_unserved_energy_total': {'display_name': 'Unserved energy', 'weight': 0.15, 'value': 0.661068104709055}, 'average_score': {'display_name': 'Score', 'weight': None, 'value': 0.84555876}}\n",
      "=========================Completed=========================\n",
      "Total time taken by agent: 0.134736655279994s\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting local evaluation\")\n",
    "num_episodes = 1\n",
    "env, wrapper_env = create_citylearn_env(schema, SubmissionReward)\n",
    "print(\"Env Created\")\n",
    "\n",
    "agent = SubmissionAgent(wrapper_env)\n",
    "\n",
    "observations = env.reset()\n",
    "\n",
    "agent_time_elapsed = 0\n",
    "\n",
    "step_start = time.perf_counter()\n",
    "actions = agent.register_reset(observations)\n",
    "agent_time_elapsed += time.perf_counter() - step_start\n",
    "\n",
    "episodes_completed = 0\n",
    "num_steps = 0\n",
    "interrupted = False\n",
    "episode_metrics = []\n",
    "try:\n",
    "    while True:\n",
    "        print('environment number of time steps:', env.time_steps)\n",
    "\n",
    "\n",
    "        ### This is only a reference script provided to allow you \n",
    "        ### to do local evaluation. The evaluator **DOES NOT** \n",
    "        ### use this script for orchestrating the evaluations. \n",
    "\n",
    "        observations, _, done, _ = env.step(actions)\n",
    "        if not done:\n",
    "            step_start = time.perf_counter()\n",
    "            actions = agent.predict(observations)\n",
    "            agent_time_elapsed += time.perf_counter()- step_start\n",
    "        else:\n",
    "            episodes_completed += 1\n",
    "            metrics_df = env.evaluate_citylearn_challenge()\n",
    "            episode_metrics.append(metrics_df)\n",
    "            print(f\"Episode complete: {episodes_completed} | Latest episode metrics: {metrics_df}\", )\n",
    "\n",
    "            # Optional: Uncomment line below to update power outage random seed \n",
    "            # from what was initially defined in schema\n",
    "            #env = update_power_outage_random_seed(env, 90000)\n",
    "\n",
    "            observations = env.reset()\n",
    "\n",
    "            step_start = time.perf_counter()\n",
    "            actions = agent.predict(observations)\n",
    "            agent_time_elapsed += time.perf_counter()- step_start\n",
    "\n",
    "        num_steps += 1\n",
    "        if num_steps % 1000 == 0:\n",
    "            print(f\"Num Steps: {num_steps}, Num episodes: {episodes_completed}\")\n",
    "\n",
    "        if episodes_completed >= num_episodes:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"========================= Stopping Evaluation =========================\")\n",
    "    interrupted = True\n",
    "\n",
    "if not interrupted:\n",
    "    print(\"=========================Completed=========================\")\n",
    "\n",
    "print(f\"Total time taken by agent: {agent_time_elapsed}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c95e440b-14cf-44f5-a29f-13858ac3a307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment number of time steps: 0\n",
      "obs: [0.         0.         0.         0.         1.         0.\n",
      " 0.         0.         0.25881905 0.96592583 0.17317849 0.18490812\n",
      " 0.84030565 0.34111083 0.         0.11842983 0.21059271 0.\n",
      " 0.         0.13568079 0.9035313  0.         0.29729488 0.48117642\n",
      " 0.0052114  0.         0.         0.2        0.         0.\n",
      " 0.00739747 0.         0.09174025 0.0106058  1.         0.44615378\n",
      " 0.        ]\n",
      "mean: None\n",
      "std: None\n",
      "721 719 256 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit/agents/SACmodel_2.py:223\u001b[0m, in \u001b[0;36mSAC_TGELU.get_normalized_observations\u001b[0;34m(self, index, observations)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_mean\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_std[index]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# self.time_step >= self.standardize_start_time_step and self.batch_size <= len(self.replay_buffer[i])\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'NoneType'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menvironment number of time steps:\u001b[39m\u001b[38;5;124m'\u001b[39m, time_step)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#actions = agent.predict(observations, deterministic=deterministic)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# apply actions to citylearn_env\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     next_observations, rewards, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "File \u001b[0;32m~/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit/agents/rbc_agent.py:46\u001b[0m, in \u001b[0;36mBasicRBCAgent.predict\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations):\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Just a passthrough, can implement any custom logic as needed \"\"\"\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit/agents/SACmodel_2.py:188\u001b[0m, in \u001b[0;36mSAC_TGELU.predict\u001b[0;34m(self, observations, deterministic)\u001b[0m\n\u001b[1;32m    185\u001b[0m deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m deterministic\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_exploration_time_step \u001b[38;5;129;01mor\u001b[39;00m deterministic:\n\u001b[0;32m--> 188\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_post_exploration_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_exploration_prediction(observations)\n",
      "File \u001b[0;32m~/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit/agents/SACmodel_2.py:204\u001b[0m, in \u001b[0;36mSAC_TGELU.get_post_exploration_prediction\u001b[0;34m(self, observations, deterministic)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(observations):\n\u001b[1;32m    203\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_encoded_observations(i, o)\n\u001b[0;32m--> 204\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_normalized_observations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     o \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(o)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    206\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net[i]\u001b[38;5;241m.\u001b[39msample(o)\n",
      "File \u001b[0;32m~/work/Neurips_CityLearn/GIT/citylearn-2023-starter-kit/agents/SACmodel_2.py:230\u001b[0m, in \u001b[0;36mSAC_TGELU.get_normalized_observations\u001b[0;34m(self, index, observations)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_std[index])\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstandardize_start_time_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 1 if episodes is None else episodes\n",
    "deterministic_finish = False if deterministic_finish is None else deterministic_finish\n",
    "deterministic = False if deterministic is None else deterministic\n",
    "#self.__set_logger(logging_level)\n",
    "\n",
    "for episode in range(episodes):\n",
    "    \n",
    "    deterministic = deterministic or (deterministic_finish and episode >= episodes - 1)\n",
    "    observations = env.reset()\n",
    "    #episode_time_steps = episode_tracker.episode_time_steps\n",
    "    done = False\n",
    "    time_step = 0\n",
    "    rewards_list = []\n",
    "    print('environment number of time steps:', time_step)\n",
    "\n",
    "\n",
    "    while not done:\n",
    "        #actions = agent.predict(observations, deterministic=deterministic)\n",
    "        actions = agent.predict(observations)\n",
    "\n",
    "        # apply actions to citylearn_env\n",
    "        next_observations, rewards, done, _ = env.step(actions)\n",
    "        rewards_list.append(rewards)\n",
    "\n",
    "                # update\n",
    "        if not deterministic:\n",
    "            agent.update(observations, actions, rewards, next_observations, done=done)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        observations = [o for o in next_observations]\n",
    "\n",
    "        #logging.debug(\n",
    "        #            f'Time step: {time_step + 1}/{self.episode_time_steps},'\\\n",
    "        #                f' Episode: {episode + 1}/{episodes},'\\\n",
    "        #                    f' Actions: {actions},'\\\n",
    "        #                        f' Rewards: {rewards}'\n",
    "        #        )\n",
    "\n",
    "        time_step += 1\n",
    "        print('environment number of time steps:', time_step)\n",
    "\n",
    "\n",
    "rewards = np.array(rewards_list, dtype='float')\n",
    "rewards_summary = {\n",
    "                'min': rewards.min(axis=0),\n",
    "                'max': rewards.max(axis=0),\n",
    "                'sum': rewards.sum(axis=0),\n",
    "                'mean': rewards.mean(axis=0)\n",
    "            }\n",
    "#logging.info(f'Completed episode: {episode + 1}/{episodes}, Reward: {rewards_summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0af49933-0ae4-4a51-a089-a7d5689355c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observations = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b802f0ed-0ccb-4dfd-811c-1d2505b8d64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, List, Mapping\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from citylearn.base import Environment\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "logging.getLogger('matplotlib.pyplot').disabled = True\n",
    "\n",
    "class Agent(Environment):\n",
    "    r\"\"\"Base agent class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : CityLearnEnv\n",
    "        CityLearn environment.\n",
    "\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    **kwargs : dict\n",
    "        Other keyword arguments used to initialize super class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env: CityLearnEnv, **kwargs: Any):\n",
    "        self.env = env\n",
    "        self.observation_names = self.env.observation_names\n",
    "        self.action_names = self.env.action_names\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.action_space = self.env.action_space\n",
    "        self.episode_time_steps = self.env.time_steps\n",
    "        self.building_metadata = self.env.get_metadata()['buildings']\n",
    "        super().__init__(\n",
    "            seconds_per_time_step=self.env.seconds_per_time_step,\n",
    "            random_seed=self.env.random_seed,\n",
    "            episode_tracker=env.episode_tracker,\n",
    "        )\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def observation_names(self) -> List[List[str]]:\n",
    "        \"\"\"Names of active observations that can be used to map observation values.\"\"\"\n",
    "\n",
    "        return self.__observation_names\n",
    "    \n",
    "    @property\n",
    "    def action_names(self) -> List[List[str]]:\n",
    "        \"\"\"Names of active actions that can be used to map action values.\"\"\"\n",
    "\n",
    "        return self.__action_names\n",
    "\n",
    "    @property\n",
    "    def observation_space(self) -> List[spaces.Box]:\n",
    "        \"\"\"Format of valid observations.\"\"\"\n",
    "\n",
    "        return self.__observation_space\n",
    "\n",
    "    @property\n",
    "    def action_space(self) -> List[spaces.Box]:\n",
    "        \"\"\"Format of valid actions.\"\"\"\n",
    "\n",
    "        return self.__action_space\n",
    "    \n",
    "    @property\n",
    "    def episode_time_steps(self) -> int:\n",
    "        return self.__episode_time_steps\n",
    "\n",
    "    @property\n",
    "    def building_metadata(self) -> List[Mapping[str, Any]]:\n",
    "        \"\"\"Building(s) metadata.\"\"\"\n",
    "\n",
    "        return self.__building_metadata\n",
    "\n",
    "    @property\n",
    "    def action_dimension(self) -> List[int]:\n",
    "        \"\"\"Number of returned actions.\"\"\"\n",
    "\n",
    "        return [s.shape[0] for s in self.action_space]\n",
    "\n",
    "    @property\n",
    "    def actions(self) -> List[List[List[Any]]]:\n",
    "        \"\"\"Action history/time series.\"\"\"\n",
    "\n",
    "        return self.__actions\n",
    "\n",
    "    @observation_names.setter\n",
    "    def observation_names(self, observation_names: List[List[str]]):\n",
    "        self.__observation_names = observation_names\n",
    "\n",
    "    @action_names.setter\n",
    "    def action_names(self, action_names: List[List[str]]):\n",
    "        self.__action_names = action_names\n",
    "\n",
    "    @observation_space.setter\n",
    "    def observation_space(self, observation_space: List[spaces.Box]):\n",
    "        self.__observation_space = observation_space\n",
    "\n",
    "    @action_space.setter\n",
    "    def action_space(self, action_space: List[spaces.Box]):\n",
    "        self.__action_space = action_space\n",
    "\n",
    "    @episode_time_steps.setter\n",
    "    def episode_time_steps(self, episode_time_steps: int):\n",
    "        \"\"\"Number of time steps in one episode.\"\"\"\n",
    "\n",
    "        self.__episode_time_steps = episode_time_steps\n",
    "\n",
    "    @building_metadata.setter\n",
    "    def building_metadata(self, building_metadata: List[Mapping[str, Any]]):\n",
    "        self.__building_metadata = building_metadata\n",
    "\n",
    "    @actions.setter\n",
    "    def actions(self, actions: List[List[Any]]):\n",
    "        for i in range(len(self.action_space)):\n",
    "            self.__actions[i][self.time_step] = actions[i]\n",
    "\n",
    "    def learn(self, episodes: int = None, deterministic: bool = None, deterministic_finish: bool = None, logging_level: int = None):\n",
    "        \"\"\"Train agent.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        episodes: int, default: 1\n",
    "            Number of training episode >= 1.\n",
    "        deterministic: bool, default: False\n",
    "            Indicator to take deterministic actions i.e. strictly exploit the learned policy.\n",
    "        deterministic_finish: bool, default: False\n",
    "            Indicator to take deterministic actions in the final episode.\n",
    "        logging_level: int, default: 30\n",
    "            Logging level where increasing the number silences lower level information.\n",
    "        \"\"\"\n",
    "        \n",
    "        episodes = 1 if episodes is None else episodes\n",
    "        deterministic_finish = False if deterministic_finish is None else deterministic_finish\n",
    "        deterministic = False if deterministic is None else deterministic\n",
    "        self.__set_logger(logging_level)\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            deterministic = deterministic or (deterministic_finish and episode >= episodes - 1)\n",
    "            observations = self.env.reset()\n",
    "            self.episode_time_steps = self.episode_tracker.episode_time_steps\n",
    "            done = False\n",
    "            time_step = 0\n",
    "            rewards_list = []\n",
    "\n",
    "            while not done:\n",
    "                actions = self.predict(observations, deterministic=deterministic)\n",
    "\n",
    "                # apply actions to citylearn_env\n",
    "                next_observations, rewards, done, _ = self.env.step(actions)\n",
    "                rewards_list.append(rewards)\n",
    "\n",
    "                # update\n",
    "                if not deterministic:\n",
    "                    self.update(observations, actions, rewards, next_observations, done=done)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                observations = [o for o in next_observations]\n",
    "\n",
    "                logging.debug(\n",
    "                    f'Time step: {time_step + 1}/{self.episode_time_steps},'\\\n",
    "                        f' Episode: {episode + 1}/{episodes},'\\\n",
    "                            f' Actions: {actions},'\\\n",
    "                                f' Rewards: {rewards}'\n",
    "                )\n",
    "\n",
    "                time_step += 1\n",
    "\n",
    "            rewards = np.array(rewards_list, dtype='float')\n",
    "            rewards_summary = {\n",
    "                'min': rewards.min(axis=0),\n",
    "                'max': rewards.max(axis=0),\n",
    "                'sum': rewards.sum(axis=0),\n",
    "                'mean': rewards.mean(axis=0)\n",
    "            }\n",
    "            logging.info(f'Completed episode: {episode + 1}/{episodes}, Reward: {rewards_summary}')\n",
    "\n",
    "    def predict(self, observations: List[List[float]], deterministic: bool = None) -> List[List[float]]:\n",
    "        \"\"\"Provide actions for current time step.\n",
    "\n",
    "        Return randomly sampled actions from `action_space`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        observations: List[List[float]]\n",
    "            Environment observations\n",
    "        deterministic: bool, default: False\n",
    "            Wether to return purely exploitatative deterministic actions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        actions: List[List[float]]\n",
    "            Action values\n",
    "        \"\"\"\n",
    "        \n",
    "        actions = [list(s.sample()) for s in self.action_space]\n",
    "        self.actions = actions\n",
    "        self.next_time_step()\n",
    "        return actions\n",
    "    \n",
    "    def __set_logger(self, logging_level: int = None):\n",
    "        \"\"\"Set logging level.\"\"\"\n",
    "\n",
    "        logging_level = 30 if logging_level is None else logging_level\n",
    "        assert logging_level >= 0, 'logging_level must be >= 0'\n",
    "        LOGGER.setLevel(logging_level)\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        \"\"\"Update replay buffer and networks.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This implementation does nothing but is kept to keep the API for all agents similar during simulation.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def next_time_step(self):\n",
    "        super().next_time_step()\n",
    "\n",
    "        for i in range(len(self.action_space)):\n",
    "            self.__actions[i].append([])\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.__actions = [[[]] for _ in self.action_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbe46d96-3eb5-411d-8cf4-e6a6341389ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WrapperEnv' object has no attribute 'reset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#observations = env.reset()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic_finish\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/citylearn/agents/base.py:140\u001b[0m, in \u001b[0;36mAgent.learn\u001b[0;34m(self, episodes, deterministic, deterministic_finish, logging_level)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes):\n\u001b[1;32m    139\u001b[0m     deterministic \u001b[38;5;241m=\u001b[39m deterministic \u001b[38;5;129;01mor\u001b[39;00m (deterministic_finish \u001b[38;5;129;01mand\u001b[39;00m episode \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m episodes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m     observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m()\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_time_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_tracker\u001b[38;5;241m.\u001b[39mepisode_time_steps\n\u001b[1;32m    142\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WrapperEnv' object has no attribute 'reset'"
     ]
    }
   ],
   "source": [
    "#observations = env.reset()\n",
    "agent.learn(episodes=2, deterministic_finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c7df133-01d6-4c7d-82fa-d6d699916ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save({\n",
    "    'model_state_dict_50ep': model.policy_net[0].state_dict(),\n",
    "    # ... add any other things you want to save\n",
    "}, \"final_model_50ep.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5a1a841-2254-4139-bb28-ccb46a89118b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = env.evaluate_citylearn_challenge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e32ec061-a807-413b-ae90-27f2b2cccf39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbon_emissions_total': {'display_name': 'Carbon emissions',\n",
       "  'weight': 0.1,\n",
       "  'value': 1.3340259310437996},\n",
       " 'discomfort_proportion': {'display_name': 'Unmet hours',\n",
       "  'weight': 0.3,\n",
       "  'value': 0.94203642184445},\n",
       " 'ramping_average': {'display_name': 'Ramping',\n",
       "  'weight': 0.075,\n",
       "  'value': 1.2004015102942642},\n",
       " 'daily_one_minus_load_factor_average': {'display_name': 'Load factor',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.8283451765974728},\n",
       " 'daily_peak_average': {'display_name': 'Daily peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 1.1438934029024024},\n",
       " 'annual_peak_average': {'display_name': 'All-time peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9784586059831769},\n",
       " 'one_minus_thermal_resilience_proportion': {'display_name': 'Thermal resilience',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.8873015873015874},\n",
       " 'power_outage_normalized_unserved_energy_total': {'display_name': 'Unserved energy',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.5987651937104977},\n",
       " 'average_score': {'display_name': 'Score',\n",
       "  'weight': None,\n",
       "  'value': 0.9502559}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "039b6e94-83a8-4e3e-82c6-27a0ef9697eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbon_emissions_total': {'display_name': 'Carbon emissions',\n",
       "  'weight': 0.1,\n",
       "  'value': 0.9524949372122796},\n",
       " 'discomfort_proportion': {'display_name': 'Unmet hours',\n",
       "  'weight': 0.3,\n",
       "  'value': 0.7072975069995903},\n",
       " 'ramping_average': {'display_name': 'Ramping',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.8822691302350596},\n",
       " 'daily_one_minus_load_factor_average': {'display_name': 'Load factor',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9432832179231083},\n",
       " 'daily_peak_average': {'display_name': 'Daily peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9289293527981298},\n",
       " 'annual_peak_average': {'display_name': 'All-time peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.9481310397646742},\n",
       " 'one_minus_thermal_resilience_proportion': {'display_name': 'Thermal resilience',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.6380952380952382},\n",
       " 'power_outage_normalized_unserved_energy_total': {'display_name': 'Unserved energy',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.624879498221464},\n",
       " 'average_score': {'display_name': 'Score',\n",
       "  'weight': None,\n",
       "  'value': 0.77458096}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd291aad-ce26-46fe-879f-88d2f0a9f11a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observations = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0490aab9-3876-4232-825c-998b80ce7fb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5,\n",
       "  1,\n",
       "  24.66,\n",
       "  24.910639,\n",
       "  38.41596,\n",
       "  27.611464,\n",
       "  0.0,\n",
       "  54.625927,\n",
       "  116.84289,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  143.32434,\n",
       "  1020.7561,\n",
       "  0.0,\n",
       "  0.40248835,\n",
       "  23.098652,\n",
       "  0.35683933,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.67788136,\n",
       "  0.02893,\n",
       "  0.02893,\n",
       "  0.02915,\n",
       "  0.02893,\n",
       "  1.1192156,\n",
       "  0.055682074,\n",
       "  3.0,\n",
       "  23.222221,\n",
       "  0],\n",
       " [5,\n",
       "  1,\n",
       "  24.66,\n",
       "  24.910639,\n",
       "  38.41596,\n",
       "  27.611464,\n",
       "  0.0,\n",
       "  54.625927,\n",
       "  116.84289,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  143.32434,\n",
       "  1020.7561,\n",
       "  0.0,\n",
       "  0.40248835,\n",
       "  24.278513,\n",
       "  0.18733284,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.18733284,\n",
       "  0.02893,\n",
       "  0.02893,\n",
       "  0.02915,\n",
       "  0.02893,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  24.444445,\n",
       "  0],\n",
       " [5,\n",
       "  1,\n",
       "  24.66,\n",
       "  24.910639,\n",
       "  38.41596,\n",
       "  27.611464,\n",
       "  0.0,\n",
       "  54.625927,\n",
       "  116.84289,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  143.32434,\n",
       "  1020.7561,\n",
       "  0.0,\n",
       "  0.40248835,\n",
       "  24.431562,\n",
       "  0.4220805,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.5631514,\n",
       "  0.02893,\n",
       "  0.02893,\n",
       "  0.02915,\n",
       "  0.02893,\n",
       "  0.5579055,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  24.444445,\n",
       "  0]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53644887-12f5-4ff1-8725-a42ccb5ec703",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.2366574 , -0.1068032 ,  0.04216267], dtype=float32),\n",
       " array([-0.3589483 ,  0.26893902,  0.36544722], dtype=float32),\n",
       " array([ 0.36875746, -0.1719276 ,  0.03730884], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.predict(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74181513-1efc-45b6-a61e-4a24cd5d792b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print cost functions at the end of episode\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m kpis \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_condition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEvaluationCondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWITHOUT_STORAGE_BUT_WITH_PARTIAL_LOAD_AND_PV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m kpis \u001b[38;5;241m=\u001b[39m kpis\u001b[38;5;241m.\u001b[39mpivot(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_function\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m kpis \u001b[38;5;241m=\u001b[39m kpis\u001b[38;5;241m.\u001b[39mdropna(how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/citylearn/citylearn.py:1007\u001b[0m, in \u001b[0;36mCityLearnEnv.evaluate\u001b[0;34m(self, control_condition, baseline_condition, comfort_band)\u001b[0m\n\u001b[1;32m    998\u001b[0m control_condition \u001b[38;5;241m=\u001b[39m EvaluationCondition\u001b[38;5;241m.\u001b[39mWITH_STORAGE_AND_PARTIAL_LOAD_AND_PV \u001b[38;5;28;01mif\u001b[39;00m control_condition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m control_condition\n\u001b[1;32m    999\u001b[0m baseline_condition \u001b[38;5;241m=\u001b[39m EvaluationCondition\u001b[38;5;241m.\u001b[39mWITHOUT_STORAGE_AND_PARTIAL_LOAD_BUT_WITH_PV \u001b[38;5;28;01mif\u001b[39;00m baseline_condition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m baseline_condition\n\u001b[1;32m   1001\u001b[0m district_level \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_function\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mramping_average\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: CostFunction\u001b[38;5;241m.\u001b[39mramping(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, control_condition))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\\\n\u001b[1;32m   1004\u001b[0m         CostFunction\u001b[38;5;241m.\u001b[39mramping(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, baseline_condition))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1005\u001b[0m }, {\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_function\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaily_one_minus_load_factor_average\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mCostFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_minus_load_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_net_electricity_consumption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_condition\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m\\\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCostFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_minus_load_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_net_electricity_consumption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_condition\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m   1009\u001b[0m },{\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_function\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly_one_minus_load_factor_average\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: CostFunction\u001b[38;5;241m.\u001b[39mone_minus_load_factor(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, control_condition), window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m730\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\\\n\u001b[1;32m   1012\u001b[0m         CostFunction\u001b[38;5;241m.\u001b[39mone_minus_load_factor(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, baseline_condition), window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m730\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1013\u001b[0m }, {\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_function\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaily_peak_average\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: CostFunction\u001b[38;5;241m.\u001b[39mpeak(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, control_condition), window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\\\n\u001b[1;32m   1016\u001b[0m         CostFunction\u001b[38;5;241m.\u001b[39mpeak(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, baseline_condition), window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1017\u001b[0m }, {\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_function\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannual_peak_average\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: CostFunction\u001b[38;5;241m.\u001b[39mpeak(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, control_condition), window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8760\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\\\n\u001b[1;32m   1020\u001b[0m         CostFunction\u001b[38;5;241m.\u001b[39mpeak(get_net_electricity_consumption(\u001b[38;5;28mself\u001b[39m, baseline_condition), window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8760\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1021\u001b[0m }])\n\u001b[1;32m   1023\u001b[0m district_level \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([district_level, building_level], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1024\u001b[0m district_level \u001b[38;5;241m=\u001b[39m district_level\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_function\u001b[39m\u001b[38;5;124m'\u001b[39m])[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# print cost functions at the end of episode\n",
    "kpis = agent.env.evaluate(baseline_condition=EvaluationCondition.WITHOUT_STORAGE_BUT_WITH_PARTIAL_LOAD_AND_PV)\n",
    "kpis = kpis.pivot(index='cost_function', columns='name', values='value')\n",
    "kpis = kpis.dropna(how='all')\n",
    "display(kpis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a6f3aab-4bc1-4aa0-bb62-cb7cf1575230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.learn(episodes=30, deterministic_finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf1e3747-cb3a-40a9-9306-9afd6dc66b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = env.evaluate_citylearn_challenge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0daa18b7-7e83-4c4a-97be-d717d029d23e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbon_emissions_total': {'display_name': 'Carbon emissions',\n",
       "  'weight': 0.1,\n",
       "  'value': 1.3800424718605893},\n",
       " 'discomfort_proportion': {'display_name': 'Unmet hours',\n",
       "  'weight': 0.3,\n",
       "  'value': 0.9435889676707184},\n",
       " 'ramping_average': {'display_name': 'Ramping',\n",
       "  'weight': 0.075,\n",
       "  'value': 1.2382565378723764},\n",
       " 'daily_one_minus_load_factor_average': {'display_name': 'Load factor',\n",
       "  'weight': 0.075,\n",
       "  'value': 0.8065937893847627},\n",
       " 'daily_peak_average': {'display_name': 'Daily peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 1.1248158576111094},\n",
       " 'annual_peak_average': {'display_name': 'All-time peak',\n",
       "  'weight': 0.075,\n",
       "  'value': 1.0453686965067146},\n",
       " 'one_minus_thermal_resilience_proportion': {'display_name': 'Thermal resilience',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.8190476190476191},\n",
       " 'power_outage_normalized_unserved_energy_total': {'display_name': 'Unserved energy',\n",
       "  'weight': 0.15,\n",
       "  'value': 0.6375529252711437},\n",
       " 'average_score': {'display_name': 'Score',\n",
       "  'weight': None,\n",
       "  'value': 0.9556986}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698374d2-13bb-46eb-b048-ce871f2f2162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
